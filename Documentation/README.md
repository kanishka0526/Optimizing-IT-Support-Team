# ğŸš€ Optimizing IT Support Team Performance Using Analytics

## ğŸ“Œ Project Overview
This project focuses on analyzing **IT Support Ticket data** to understand customer issues, optimize resolution time, and improve overall support service efficiency using **data analytics and visualization tools**.

The project involves **data extraction, cleaning, exploratory analysis, and dashboard creation** using Power BI and Python.

---

## ğŸ—“ï¸ Weekly Work Breakdown

---

## ğŸ“… Week 1: Project Introduction & Power BI Fundamentals

### ğŸ”¹ Activities
- Self-introduction and overview of the project
- Explanation of real-world IT support scenarios:
  - Customers face transaction issues such as delayed money transfer or difficulty fetching transaction details
  - Such issues are raised as **support tickets** by customers
- Introduction to **Power BI**:
  - Ribbon
  - Power Query
  - Report (Visual) View
  - Table View
  - Model View
- Extracted datasets from different websites
- Performed data cleaning using **Power Query**

### ğŸ”¹ Data Cleaning Steps (Power BI)
- Removed duplicate records
- Handled missing values using aggregation where applicable
- Removed unnecessary columns
- Standardized column values
- Rearranged columns
- Replaced incorrect values
- Removed white spaces using **Trim**
- Removed special characters using **Replace Values**
- Split columns using **Delimiter**

### âœ… Task
- Extracted and cleaned dataset using **Power BI Power Query**

---

## ğŸ“… Week 2: Python, Pandas & Data Cleaning in VS Code

### ğŸ”¹ Activities
- Presented cleaned dataset from Week 1
- VS Code setup and explanation of project folder structure
- Introduction to **Jupyter Notebook (.ipynb)**
- Explanation of **DataFrame** and **Pandas library**

### ğŸ”¹ Key Concepts
- **DataFrame:** A tabular structure used to store and analyze data in Python
- **Pandas:** A Python library used to load and manipulate CSV and Excel datasets

### ğŸ”¹ Data Cleaning Using Python (Pandas)
- Loaded dataset using Pandas
- Removed duplicate records
- Removed white spaces and special characters
- Replaced categorical values (Yes/No â†’ Y/N)
- Removed unnecessary rows and columns
- Filled null values
- Filtered invalid records
- Reset index and renamed columns

### âœ… Task
- Data cleaning and preprocessing using **Python (Pandas)** on customer call list dataset

---

## ğŸ“… Week 3: Exploratory Data Analysis (EDA)

### ğŸ”¹ Introduction to EDA
- EDA (Exploratory Data Analysis) helps explore, understand, and summarize data before visualization
- Without EDA â†’ dashboards are just charts
- With EDA â†’ dashboards answer business questions

### ğŸ”¹ Key Factors of EDA
- Data volume
- Data distribution
- Comparisons
- Relationships between variables

### ğŸ”¹ Activities
- Framed analytical questions based on dataset
- Reviewed data patterns and trends for dashboard creation

### âœ… Task
- Dataset review and EDA planning

---

## ğŸ“… Week 4: Live Data, APIs & GitHub

### ğŸ”¹ Activities
- Imported live data into Power BI using **Get Data â†’ Web**
- Understood challenges of live data refresh and data flooding
- Compared public and restricted datasets:
  - W3Schools (public)
  - NSE Stocks (restricted)
- Learned API concepts:
  - API Endpoint as a URL used by systems to fetch data
- Introduction to **Zendesk**:
  - Ticket creation
  - Ticket assignment
  - Status tracking
  - Performance measurement
- Example use case: Late order â†’ ticket created in Zendesk
- Created and managed **GitHub repository**

### âœ… Task
- Created GitHub repository and structured project files

---

## ğŸ› ï¸ Tools & Technologies Used
- Power BI
- Python
- Pandas
- VS Code
- Jupyter Notebook
- GitHub

---

## ğŸ“Œ Learning Outcomes
- Hands-on experience with **data cleaning, EDA, and visualization**
- Understanding of real-world IT support ticket systems
- Improved analytical and problem-solving skills
- Practical exposure to Power BI, Python, APIs, and GitHub

---

## âœ… Conclusion
This project demonstrates how **data analytics and visualization** can be used to analyze IT support operations, identify inefficiencies, and support data-driven decision-making for improving service performance.
